{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn \n",
    "import torchvision\n",
    "from torchvision.models import vit_l_16\n",
    "from torchvision.models import ViT_L_16_Weights\n",
    "\n",
    "model = torchvision.models.vit_l_16(weights = ViT_L_16_Weights.IMAGENET1K_V1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'generator'>\n",
      "\n",
      "conv_proj\n",
      "encoder\n",
      "encoder.dropout\n",
      "encoder.layers\n",
      "encoder.layers.encoder_layer_0\n",
      "encoder.layers.encoder_layer_0.ln_1\n",
      "encoder.layers.encoder_layer_0.self_attention\n",
      "encoder.layers.encoder_layer_0.self_attention.out_proj\n",
      "encoder.layers.encoder_layer_0.dropout\n",
      "encoder.layers.encoder_layer_0.ln_2\n",
      "encoder.layers.encoder_layer_0.mlp\n",
      "encoder.layers.encoder_layer_0.mlp.0\n",
      "encoder.layers.encoder_layer_0.mlp.1\n",
      "encoder.layers.encoder_layer_0.mlp.2\n",
      "encoder.layers.encoder_layer_0.mlp.3\n",
      "encoder.layers.encoder_layer_0.mlp.4\n",
      "encoder.layers.encoder_layer_1\n",
      "encoder.layers.encoder_layer_1.ln_1\n",
      "encoder.layers.encoder_layer_1.self_attention\n",
      "encoder.layers.encoder_layer_1.self_attention.out_proj\n",
      "encoder.layers.encoder_layer_1.dropout\n",
      "encoder.layers.encoder_layer_1.ln_2\n",
      "encoder.layers.encoder_layer_1.mlp\n",
      "encoder.layers.encoder_layer_1.mlp.0\n",
      "encoder.layers.encoder_layer_1.mlp.1\n",
      "encoder.layers.encoder_layer_1.mlp.2\n",
      "encoder.layers.encoder_layer_1.mlp.3\n",
      "encoder.layers.encoder_layer_1.mlp.4\n",
      "encoder.layers.encoder_layer_2\n",
      "encoder.layers.encoder_layer_2.ln_1\n",
      "encoder.layers.encoder_layer_2.self_attention\n",
      "encoder.layers.encoder_layer_2.self_attention.out_proj\n",
      "encoder.layers.encoder_layer_2.dropout\n",
      "encoder.layers.encoder_layer_2.ln_2\n",
      "encoder.layers.encoder_layer_2.mlp\n",
      "encoder.layers.encoder_layer_2.mlp.0\n",
      "encoder.layers.encoder_layer_2.mlp.1\n",
      "encoder.layers.encoder_layer_2.mlp.2\n",
      "encoder.layers.encoder_layer_2.mlp.3\n",
      "encoder.layers.encoder_layer_2.mlp.4\n",
      "encoder.layers.encoder_layer_3\n",
      "encoder.layers.encoder_layer_3.ln_1\n",
      "encoder.layers.encoder_layer_3.self_attention\n",
      "encoder.layers.encoder_layer_3.self_attention.out_proj\n",
      "encoder.layers.encoder_layer_3.dropout\n",
      "encoder.layers.encoder_layer_3.ln_2\n",
      "encoder.layers.encoder_layer_3.mlp\n",
      "encoder.layers.encoder_layer_3.mlp.0\n",
      "encoder.layers.encoder_layer_3.mlp.1\n",
      "encoder.layers.encoder_layer_3.mlp.2\n",
      "encoder.layers.encoder_layer_3.mlp.3\n",
      "encoder.layers.encoder_layer_3.mlp.4\n",
      "encoder.layers.encoder_layer_4\n",
      "encoder.layers.encoder_layer_4.ln_1\n",
      "encoder.layers.encoder_layer_4.self_attention\n",
      "encoder.layers.encoder_layer_4.self_attention.out_proj\n",
      "encoder.layers.encoder_layer_4.dropout\n",
      "encoder.layers.encoder_layer_4.ln_2\n",
      "encoder.layers.encoder_layer_4.mlp\n",
      "encoder.layers.encoder_layer_4.mlp.0\n",
      "encoder.layers.encoder_layer_4.mlp.1\n",
      "encoder.layers.encoder_layer_4.mlp.2\n",
      "encoder.layers.encoder_layer_4.mlp.3\n",
      "encoder.layers.encoder_layer_4.mlp.4\n",
      "encoder.layers.encoder_layer_5\n",
      "encoder.layers.encoder_layer_5.ln_1\n",
      "encoder.layers.encoder_layer_5.self_attention\n",
      "encoder.layers.encoder_layer_5.self_attention.out_proj\n",
      "encoder.layers.encoder_layer_5.dropout\n",
      "encoder.layers.encoder_layer_5.ln_2\n",
      "encoder.layers.encoder_layer_5.mlp\n",
      "encoder.layers.encoder_layer_5.mlp.0\n",
      "encoder.layers.encoder_layer_5.mlp.1\n",
      "encoder.layers.encoder_layer_5.mlp.2\n",
      "encoder.layers.encoder_layer_5.mlp.3\n",
      "encoder.layers.encoder_layer_5.mlp.4\n",
      "encoder.layers.encoder_layer_6\n",
      "encoder.layers.encoder_layer_6.ln_1\n",
      "encoder.layers.encoder_layer_6.self_attention\n",
      "encoder.layers.encoder_layer_6.self_attention.out_proj\n",
      "encoder.layers.encoder_layer_6.dropout\n",
      "encoder.layers.encoder_layer_6.ln_2\n",
      "encoder.layers.encoder_layer_6.mlp\n",
      "encoder.layers.encoder_layer_6.mlp.0\n",
      "encoder.layers.encoder_layer_6.mlp.1\n",
      "encoder.layers.encoder_layer_6.mlp.2\n",
      "encoder.layers.encoder_layer_6.mlp.3\n",
      "encoder.layers.encoder_layer_6.mlp.4\n",
      "encoder.layers.encoder_layer_7\n",
      "encoder.layers.encoder_layer_7.ln_1\n",
      "encoder.layers.encoder_layer_7.self_attention\n",
      "encoder.layers.encoder_layer_7.self_attention.out_proj\n",
      "encoder.layers.encoder_layer_7.dropout\n",
      "encoder.layers.encoder_layer_7.ln_2\n",
      "encoder.layers.encoder_layer_7.mlp\n",
      "encoder.layers.encoder_layer_7.mlp.0\n",
      "encoder.layers.encoder_layer_7.mlp.1\n",
      "encoder.layers.encoder_layer_7.mlp.2\n",
      "encoder.layers.encoder_layer_7.mlp.3\n",
      "encoder.layers.encoder_layer_7.mlp.4\n",
      "encoder.layers.encoder_layer_8\n",
      "encoder.layers.encoder_layer_8.ln_1\n",
      "encoder.layers.encoder_layer_8.self_attention\n",
      "encoder.layers.encoder_layer_8.self_attention.out_proj\n",
      "encoder.layers.encoder_layer_8.dropout\n",
      "encoder.layers.encoder_layer_8.ln_2\n",
      "encoder.layers.encoder_layer_8.mlp\n",
      "encoder.layers.encoder_layer_8.mlp.0\n",
      "encoder.layers.encoder_layer_8.mlp.1\n",
      "encoder.layers.encoder_layer_8.mlp.2\n",
      "encoder.layers.encoder_layer_8.mlp.3\n",
      "encoder.layers.encoder_layer_8.mlp.4\n",
      "encoder.layers.encoder_layer_9\n",
      "encoder.layers.encoder_layer_9.ln_1\n",
      "encoder.layers.encoder_layer_9.self_attention\n",
      "encoder.layers.encoder_layer_9.self_attention.out_proj\n",
      "encoder.layers.encoder_layer_9.dropout\n",
      "encoder.layers.encoder_layer_9.ln_2\n",
      "encoder.layers.encoder_layer_9.mlp\n",
      "encoder.layers.encoder_layer_9.mlp.0\n",
      "encoder.layers.encoder_layer_9.mlp.1\n",
      "encoder.layers.encoder_layer_9.mlp.2\n",
      "encoder.layers.encoder_layer_9.mlp.3\n",
      "encoder.layers.encoder_layer_9.mlp.4\n",
      "encoder.layers.encoder_layer_10\n",
      "encoder.layers.encoder_layer_10.ln_1\n",
      "encoder.layers.encoder_layer_10.self_attention\n",
      "encoder.layers.encoder_layer_10.self_attention.out_proj\n",
      "encoder.layers.encoder_layer_10.dropout\n",
      "encoder.layers.encoder_layer_10.ln_2\n",
      "encoder.layers.encoder_layer_10.mlp\n",
      "encoder.layers.encoder_layer_10.mlp.0\n",
      "encoder.layers.encoder_layer_10.mlp.1\n",
      "encoder.layers.encoder_layer_10.mlp.2\n",
      "encoder.layers.encoder_layer_10.mlp.3\n",
      "encoder.layers.encoder_layer_10.mlp.4\n",
      "encoder.layers.encoder_layer_11\n",
      "encoder.layers.encoder_layer_11.ln_1\n",
      "encoder.layers.encoder_layer_11.self_attention\n",
      "encoder.layers.encoder_layer_11.self_attention.out_proj\n",
      "encoder.layers.encoder_layer_11.dropout\n",
      "encoder.layers.encoder_layer_11.ln_2\n",
      "encoder.layers.encoder_layer_11.mlp\n",
      "encoder.layers.encoder_layer_11.mlp.0\n",
      "encoder.layers.encoder_layer_11.mlp.1\n",
      "encoder.layers.encoder_layer_11.mlp.2\n",
      "encoder.layers.encoder_layer_11.mlp.3\n",
      "encoder.layers.encoder_layer_11.mlp.4\n",
      "encoder.layers.encoder_layer_12\n",
      "encoder.layers.encoder_layer_12.ln_1\n",
      "encoder.layers.encoder_layer_12.self_attention\n",
      "encoder.layers.encoder_layer_12.self_attention.out_proj\n",
      "encoder.layers.encoder_layer_12.dropout\n",
      "encoder.layers.encoder_layer_12.ln_2\n",
      "encoder.layers.encoder_layer_12.mlp\n",
      "encoder.layers.encoder_layer_12.mlp.0\n",
      "encoder.layers.encoder_layer_12.mlp.1\n",
      "encoder.layers.encoder_layer_12.mlp.2\n",
      "encoder.layers.encoder_layer_12.mlp.3\n",
      "encoder.layers.encoder_layer_12.mlp.4\n",
      "encoder.layers.encoder_layer_13\n",
      "encoder.layers.encoder_layer_13.ln_1\n",
      "encoder.layers.encoder_layer_13.self_attention\n",
      "encoder.layers.encoder_layer_13.self_attention.out_proj\n",
      "encoder.layers.encoder_layer_13.dropout\n",
      "encoder.layers.encoder_layer_13.ln_2\n",
      "encoder.layers.encoder_layer_13.mlp\n",
      "encoder.layers.encoder_layer_13.mlp.0\n",
      "encoder.layers.encoder_layer_13.mlp.1\n",
      "encoder.layers.encoder_layer_13.mlp.2\n",
      "encoder.layers.encoder_layer_13.mlp.3\n",
      "encoder.layers.encoder_layer_13.mlp.4\n",
      "encoder.layers.encoder_layer_14\n",
      "encoder.layers.encoder_layer_14.ln_1\n",
      "encoder.layers.encoder_layer_14.self_attention\n",
      "encoder.layers.encoder_layer_14.self_attention.out_proj\n",
      "encoder.layers.encoder_layer_14.dropout\n",
      "encoder.layers.encoder_layer_14.ln_2\n",
      "encoder.layers.encoder_layer_14.mlp\n",
      "encoder.layers.encoder_layer_14.mlp.0\n",
      "encoder.layers.encoder_layer_14.mlp.1\n",
      "encoder.layers.encoder_layer_14.mlp.2\n",
      "encoder.layers.encoder_layer_14.mlp.3\n",
      "encoder.layers.encoder_layer_14.mlp.4\n",
      "encoder.layers.encoder_layer_15\n",
      "encoder.layers.encoder_layer_15.ln_1\n",
      "encoder.layers.encoder_layer_15.self_attention\n",
      "encoder.layers.encoder_layer_15.self_attention.out_proj\n",
      "encoder.layers.encoder_layer_15.dropout\n",
      "encoder.layers.encoder_layer_15.ln_2\n",
      "encoder.layers.encoder_layer_15.mlp\n",
      "encoder.layers.encoder_layer_15.mlp.0\n",
      "encoder.layers.encoder_layer_15.mlp.1\n",
      "encoder.layers.encoder_layer_15.mlp.2\n",
      "encoder.layers.encoder_layer_15.mlp.3\n",
      "encoder.layers.encoder_layer_15.mlp.4\n",
      "encoder.layers.encoder_layer_16\n",
      "encoder.layers.encoder_layer_16.ln_1\n",
      "encoder.layers.encoder_layer_16.self_attention\n",
      "encoder.layers.encoder_layer_16.self_attention.out_proj\n",
      "encoder.layers.encoder_layer_16.dropout\n",
      "encoder.layers.encoder_layer_16.ln_2\n",
      "encoder.layers.encoder_layer_16.mlp\n",
      "encoder.layers.encoder_layer_16.mlp.0\n",
      "encoder.layers.encoder_layer_16.mlp.1\n",
      "encoder.layers.encoder_layer_16.mlp.2\n",
      "encoder.layers.encoder_layer_16.mlp.3\n",
      "encoder.layers.encoder_layer_16.mlp.4\n",
      "encoder.layers.encoder_layer_17\n",
      "encoder.layers.encoder_layer_17.ln_1\n",
      "encoder.layers.encoder_layer_17.self_attention\n",
      "encoder.layers.encoder_layer_17.self_attention.out_proj\n",
      "encoder.layers.encoder_layer_17.dropout\n",
      "encoder.layers.encoder_layer_17.ln_2\n",
      "encoder.layers.encoder_layer_17.mlp\n",
      "encoder.layers.encoder_layer_17.mlp.0\n",
      "encoder.layers.encoder_layer_17.mlp.1\n",
      "encoder.layers.encoder_layer_17.mlp.2\n",
      "encoder.layers.encoder_layer_17.mlp.3\n",
      "encoder.layers.encoder_layer_17.mlp.4\n",
      "encoder.layers.encoder_layer_18\n",
      "encoder.layers.encoder_layer_18.ln_1\n",
      "encoder.layers.encoder_layer_18.self_attention\n",
      "encoder.layers.encoder_layer_18.self_attention.out_proj\n",
      "encoder.layers.encoder_layer_18.dropout\n",
      "encoder.layers.encoder_layer_18.ln_2\n",
      "encoder.layers.encoder_layer_18.mlp\n",
      "encoder.layers.encoder_layer_18.mlp.0\n",
      "encoder.layers.encoder_layer_18.mlp.1\n",
      "encoder.layers.encoder_layer_18.mlp.2\n",
      "encoder.layers.encoder_layer_18.mlp.3\n",
      "encoder.layers.encoder_layer_18.mlp.4\n",
      "encoder.layers.encoder_layer_19\n",
      "encoder.layers.encoder_layer_19.ln_1\n",
      "encoder.layers.encoder_layer_19.self_attention\n",
      "encoder.layers.encoder_layer_19.self_attention.out_proj\n",
      "encoder.layers.encoder_layer_19.dropout\n",
      "encoder.layers.encoder_layer_19.ln_2\n",
      "encoder.layers.encoder_layer_19.mlp\n",
      "encoder.layers.encoder_layer_19.mlp.0\n",
      "encoder.layers.encoder_layer_19.mlp.1\n",
      "encoder.layers.encoder_layer_19.mlp.2\n",
      "encoder.layers.encoder_layer_19.mlp.3\n",
      "encoder.layers.encoder_layer_19.mlp.4\n",
      "encoder.layers.encoder_layer_20\n",
      "encoder.layers.encoder_layer_20.ln_1\n",
      "encoder.layers.encoder_layer_20.self_attention\n",
      "encoder.layers.encoder_layer_20.self_attention.out_proj\n",
      "encoder.layers.encoder_layer_20.dropout\n",
      "encoder.layers.encoder_layer_20.ln_2\n",
      "encoder.layers.encoder_layer_20.mlp\n",
      "encoder.layers.encoder_layer_20.mlp.0\n",
      "encoder.layers.encoder_layer_20.mlp.1\n",
      "encoder.layers.encoder_layer_20.mlp.2\n",
      "encoder.layers.encoder_layer_20.mlp.3\n",
      "encoder.layers.encoder_layer_20.mlp.4\n",
      "encoder.layers.encoder_layer_21\n",
      "encoder.layers.encoder_layer_21.ln_1\n",
      "encoder.layers.encoder_layer_21.self_attention\n",
      "encoder.layers.encoder_layer_21.self_attention.out_proj\n",
      "encoder.layers.encoder_layer_21.dropout\n",
      "encoder.layers.encoder_layer_21.ln_2\n",
      "encoder.layers.encoder_layer_21.mlp\n",
      "encoder.layers.encoder_layer_21.mlp.0\n",
      "encoder.layers.encoder_layer_21.mlp.1\n",
      "encoder.layers.encoder_layer_21.mlp.2\n",
      "encoder.layers.encoder_layer_21.mlp.3\n",
      "encoder.layers.encoder_layer_21.mlp.4\n",
      "encoder.layers.encoder_layer_22\n",
      "encoder.layers.encoder_layer_22.ln_1\n",
      "encoder.layers.encoder_layer_22.self_attention\n",
      "encoder.layers.encoder_layer_22.self_attention.out_proj\n",
      "encoder.layers.encoder_layer_22.dropout\n",
      "encoder.layers.encoder_layer_22.ln_2\n",
      "encoder.layers.encoder_layer_22.mlp\n",
      "encoder.layers.encoder_layer_22.mlp.0\n",
      "encoder.layers.encoder_layer_22.mlp.1\n",
      "encoder.layers.encoder_layer_22.mlp.2\n",
      "encoder.layers.encoder_layer_22.mlp.3\n",
      "encoder.layers.encoder_layer_22.mlp.4\n",
      "encoder.layers.encoder_layer_23\n",
      "encoder.layers.encoder_layer_23.ln_1\n",
      "encoder.layers.encoder_layer_23.self_attention\n",
      "encoder.layers.encoder_layer_23.self_attention.out_proj\n",
      "encoder.layers.encoder_layer_23.dropout\n",
      "encoder.layers.encoder_layer_23.ln_2\n",
      "encoder.layers.encoder_layer_23.mlp\n",
      "encoder.layers.encoder_layer_23.mlp.0\n",
      "encoder.layers.encoder_layer_23.mlp.1\n",
      "encoder.layers.encoder_layer_23.mlp.2\n",
      "encoder.layers.encoder_layer_23.mlp.3\n",
      "encoder.layers.encoder_layer_23.mlp.4\n",
      "encoder.ln\n",
      "heads\n",
      "heads.head\n"
     ]
    }
   ],
   "source": [
    "print(type(model.named_children()))\n",
    "\n",
    "for foo1,foo2 in model.named_modules():\n",
    "    print(foo1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how to use hooks \n",
    "# https://medium.com/the-dl/how-to-use-pytorch-hooks-5041d777f904\n",
    "\n",
    "class tinymodel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.hooks = [4, 11, 17, 23]\n",
    "        self.model = torchvision.models.vit_l_16(weights=ViT_L_16_Weights.IMAGENET1K_V1)\n",
    "        \n",
    "        # Access the encoder\n",
    "        self.encoder = self.model.encoder.layers\n",
    "        \n",
    "        # Ensure the encoder has the layers we expect\n",
    "        assert hasattr(self.encoder, f'encoder_layer_0'), \"Encoder layer naming is inconsistent!\"\n",
    "        self.features = {}\n",
    "\n",
    "        # Register forward hooks\n",
    "        for hook in self.hooks:\n",
    "            layer_name = f'encoder_layer_{hook}'\n",
    "            if hasattr(self.encoder, layer_name):\n",
    "                getattr(self.encoder, layer_name).register_forward_hook(self.save_output_hook(layer_name))\n",
    "            else:\n",
    "                print(f\"Warning: {layer_name} not found in encoder layers.\")\n",
    "            \n",
    "    def save_output_hook(self, layer_key):\n",
    "        def save_output(_, __, output):\n",
    "            self.features[layer_key] = output\n",
    "        return save_output\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.model(x)\n",
    "        return self.features\n",
    "\n",
    "\n",
    "\n",
    "silly_model = tinymodel()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy = torch.randn(size=(10,3,224,224)) # i think it should receive (B,C,W,H)? docs says \"Accepts PIL.Image, batched (B, C, H, W)\" \n",
    "out = silly_model(dummy)\n",
    "\n",
    "assert len(out) == len(silly_model.hooks), print(f'size of the output : {len(out)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 197, 1024])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the transformer's output shape should be (B, number_of_patches, embedding_dimension)\n",
    "# We set B as 10 [OK]\n",
    "# Number of patches = 224x224 / 16x16 = 196 . Plus +1 class token = 197 patches(ATT: class token is at [..,0,..])\n",
    "# embedding dimension = 1024 [OK]\n",
    "out['encoder_layer_4'].shape \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 196, 1024])\n",
      "torch.Size([10, 1024, 14, 14])\n",
      "torch.Size([10, 197, 1024])\n"
     ]
    }
   ],
   "source": [
    "# in the Reassemble block, we must get rid of the `class token`\n",
    "def Reassemble(out):\n",
    "    \"\"\"\n",
    "    out size is (B, number of patches + class token, embedding dimension)\n",
    "    out.shape = (B,Patches,D)\n",
    "    I  want out.shape to be (B,D,16,16)\n",
    "    \"\"\"\n",
    "    res = out[:,1:,:] # 196 patches\n",
    "    print(res.shape)\n",
    "    res = torch.reshape(res,(res.shape[0],res.shape[-1],14,14))\n",
    "    print(res.shape)\n",
    "    return res\n",
    "\n",
    "tmr = Reassemble(out['encoder_layer_4'])\n",
    "print(out['encoder_layer_4'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CLIP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
