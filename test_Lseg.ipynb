{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Lseg.utils.util import get_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tMapping ade20k-150 -> universal\n",
      "\tMapping bdd -> universal\n",
      "\tMapping cityscapes-19 -> universal\n",
      "\tMapping coco-panoptic-133 -> universal\n",
      "\tMapping idd-39 -> universal\n",
      "\tMapping mapillary-public65 -> universal\n",
      "\tMapping sunrgbd-37 -> universal\n",
      "\tMapping ade20k-150-relabeled -> universal\n",
      "\tMapping bdd-relabeled -> universal\n",
      "\tMapping cityscapes-19-relabeled -> universal\n",
      "\tMapping cityscapes-34-relabeled -> universal\n",
      "\tMapping coco-panoptic-133-relabeled -> universal\n",
      "\tMapping idd-39-relabeled -> universal\n",
      "\tMapping mapillary-public65-relabeled -> universal\n",
      "\tMapping sunrgbd-37-relabeled -> universal\n",
      "\n",
      "\tCreating 1x1 conv for test datasets...\n",
      "Totally 20210 samples in train set.\n",
      "Checking image&label pair train list done!\n",
      "image folder path: data/mseg_dataset/ADE20K/ADEChallengeData2016/\n",
      "text path: mseg-api/mseg/dataset_lists/ade20k-150-relabeled/list/train.txt\n"
     ]
    }
   ],
   "source": [
    "dataset = get_dataset(dataset_name='ade20k', get_train=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "torch.Size([3, 320, 320]) torch.Size([320, 320])\n"
     ]
    }
   ],
   "source": [
    "print(type(dataset[0][0]), type(dataset[0][1]))\n",
    "print(dataset[0][0].shape, dataset[0][1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 36,  43,  64,  89, 125, 144, 162, 163, 167, 174, 191, 194])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "# obtain the number annotations for the first image\n",
    "labels = torch.unique(dataset[0][1])\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ceiling\n",
      "floor\n",
      "potted_plant\n",
      "escalator\n",
      "person\n",
      "fence\n",
      "column\n",
      "fountain\n",
      "flag\n",
      "vegetation\n",
      "wall\n",
      "unlabeled\n"
     ]
    }
   ],
   "source": [
    "from Lseg.utils.util import ToUniversalLabel, semantic_label_tsv_path\n",
    "\n",
    "# get the univeral labeling after all the images have been relabeled\n",
    "universal_label = ToUniversalLabel.read_MSeg_master(semantic_label_tsv_path)\n",
    "\n",
    "# get the text annotation of the first image \n",
    "for idx in labels:\n",
    "    print(universal_label[int(idx)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CLIP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
